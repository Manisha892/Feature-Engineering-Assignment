{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec651568-8615-4a6a-8cf5-9ff95930ec5e",
   "metadata": {},
   "source": [
    "## Question (1) What is a parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66b90f-8007-4b2d-a1e4-686867823ed7",
   "metadata": {},
   "source": [
    "Answer :\n",
    "* In machine learning, a parameter is a variable that a model learns from data during training to make \n",
    "  predictions.\n",
    "* A model parameter is a configuration variable that's internal to the model and is used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356b3c7-327b-44bd-ad89-05a32444400a",
   "metadata": {},
   "source": [
    "## Question (2) What is correlation? What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c918c9c-a4c2-4e77-abea-579add7c57ac",
   "metadata": {},
   "source": [
    "Answer :\n",
    "#### Correlation\n",
    "* A correlation is the statistical summary of the relationship between two sets of variables.\n",
    "* It is a core part of data exploratory analysis,and is a critical aspect of numerous advanced machine\n",
    "  learning techniques.\n",
    "* Correlation coefficients are used to measure how well two variables are related. \n",
    "* The correlation coefficient ranges from -1 to 1, with -1 indicating a perfect negative correlation,\n",
    "  1 indicating a perfect positive correlation, and 0 indicating no correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5973be98-fa1a-4df1-bdde-f86aca64aabd",
   "metadata": {},
   "source": [
    "#### Negative Correlation\n",
    "* A negative correlation is a relationship between two variables that move in opposite directions. \n",
    "* In other words, when variable A increases, variable B decreases.\n",
    "* A negative correlation is also known as an inverse correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53635b73-e0f6-4849-ae35-0526e7717435",
   "metadata": {},
   "source": [
    "## Question (3) Define Machine Learning. What are the main components in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc973d2-663b-4062-9a36-2a77c0a24c35",
   "metadata": {},
   "source": [
    "Answer :\n",
    "#### Machine Learning\n",
    "* Machine learning is a subset of AI, which uses algorithms that learn from data to make predictions. \n",
    "  These predictions can be generated through supervised learning, where algorithms learn patterns from \n",
    "  existing data,or unsupervised learning, where they discover general patterns in data.\n",
    "* Machine learning and associated algorithms and techniques fundamentally involve designing, implementing, \n",
    "  and training algorithms to recognize patterns in exposed data and perform predictions or classifications.\n",
    "\n",
    "#### Defination according to Arthur Samual(1959)\n",
    "* Arthur Samuel, an AI pioneer, defined machine learning as \"the field of study that gives computers the \n",
    "  ability to learn without being explicitly programmed\". Samuel's work in the 1950s demonstrated that \n",
    "  computers could learn by teaching a program to play checkers. The program could learn from its mistakes \n",
    "  and improve its performance, without being explicitly designed to carry out specific commands. \r",
    "* \n",
    "Machine learning is a computational method that uses experience to improve performance or mak \n",
    "   predictions The quality and amount of data is crucial to the accuracy of the predictions.\n",
    "\n",
    "#### Tom Mitchell(1997)\n",
    "* Tom Mitchell defines machine learning (ML) as the study of computer programs that can learn from data and \n",
    "  improve their performance without being explicitly programmed. Mitchell's definition emphasizes the \n",
    "  importance of data and the ability of algorithms to adapt based on experience.  \n",
    "\n",
    "#### The main components of machine learning are\n",
    "* Representation : How Data is viewed.\n",
    "* Evaluation : How Hypotheses are evaluated.\n",
    "* Optimization : The Prosess of generating hypotheses.\n",
    "\n",
    "#### Other key components of Machine Learning include :\n",
    "* Algorithems,Data,Models,Predictions : A Crucial component for the functinality and effectiveness of ML \n",
    "  systems.L systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d05f0d-fd4b-4701-a5d9-fd4b613646fa",
   "metadata": {},
   "source": [
    "## Question(4) How does loss value help in determining whether the model is good or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ba60c-6f81-4e32-98a5-a70253af4491",
   "metadata": {},
   "source": [
    "Answer : \n",
    "\n",
    "* In statistics and machine learning, loss measures the difference between the predicted and actual values.\n",
    "   Loss focuses on the distance between the values, not the direction. \n",
    "\n",
    "* For example: If a model predicts 2, but the actual value is 5, we don't care that the loss is\n",
    "               negative ( 2 − 5 = − 3 ).\n",
    "\n",
    "* The loss function is a mathematical process that quantifies the error margin between a model's \n",
    "   prediction and the actual target value.\n",
    "\n",
    "* Machine learning algorithms learn through different methods, but a fundamental component of the learning\n",
    "   process of machine learning algorithms and models is the loss function.\n",
    "   The loss function is a mathematical process that quantifies the error margin between a model's prediction\n",
    "   and the actual target value.\n",
    "\n",
    "* The loss value in machine learning is a quantitative measure of how well a model's predictions match the \n",
    "   actual targets.It plays a crucial role in determining the performance and quality of a model during \n",
    "   training and evaluation.\n",
    "\n",
    "  ### Here's how it helps determine whether the model is \"good\" or not:\n",
    "\n",
    "    * 1. What is a Loss Value : The loss value is computed using a loss function, which measures the \n",
    "                                difference between the model's predicted outputs and the true outputs \n",
    "                                (ground truth).\n",
    "               * Common examples include:\n",
    "                 * Mean Squared Error (MSE) for regression tasks.\n",
    "                 * Cross-Entropy Loss for classification tasks.\n",
    "             \n",
    "          A lower loss value indicates that the model's predictions are closer to the true values.\n",
    "                               \n",
    "    * 2. Key Insights from the Loss Value :\n",
    "         * Training Progress: During training, the loss value is used to monitor how well the model is\n",
    "                             learning. A decreasing loss over epochs indicates that the model is improving.\n",
    "                               \n",
    "         * Optimization: Loss values are used by optimization algorithms (e.g., gradient descent) to adjust \n",
    "                        the model's parameters and minimize errors.\n",
    "                               \n",
    "         * Overfitting or Underfitting:\n",
    "            * If the training loss decreases but the validation loss increases, it may indicate overfitting.\n",
    "            * If both training and validation losses remain high, the model might be underfitting.\n",
    "\n",
    "    * 3. Comparing Models : The loss value allows comparison between models:\n",
    "          * Lower Loss is Better: Between two models trained on the same dataset and task, the one with the \n",
    "                                  lower loss is generally better.\n",
    "                                                                 \n",
    "          * Baseline Comparison: Loss values can be compared against a baseline  to evaluate the improvement. \n",
    "                                 (e.g., a model that predicts the mean or random guesses) \n",
    "\n",
    "    * 4. Limitations of Loss Values : While useful, the loss value alone does not tell the whole story:\n",
    "          * Evaluation Metrics: Metrics like accuracy, precision, recall, F1-score, etc., are often more\n",
    "                                interpretable and task-specific indicators of model quality.\n",
    "                                                                 \n",
    "          * Scale Dependence: The loss value's magnitude depends on the loss function used.For instance, MSE\n",
    "                                loss can range widely and isn't comparable across tasks or datasets.\n",
    "                                                                 \n",
    "          * Data Balance: Imbalanced datasets may show low loss but poor performance for minority classes.\n",
    "\n",
    "    * 5. Practical Use : To determine if a model is \"good,\" consider:\n",
    "\n",
    "          * The loss trend (decreasing over epochs).\n",
    "          * The comparison between training and validation loss.\n",
    "          * Evaluation using task-specific metrics alongside the loss.\n",
    "                                                                                    \n",
    "         By combining loss value analysis with other metrics, you get a clearer picture of model \n",
    "            performance and quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63b352-4e58-48cd-a5cf-0d33cace01a2",
   "metadata": {},
   "source": [
    "## Question(5) What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c922b-45e0-41ef-b847-1e872ad4576f",
   "metadata": {},
   "source": [
    "Answer : \n",
    "Continuous variables are values that can take on any value within a range, while categorical variables are \n",
    "descriptive and not numerical: \n",
    "\n",
    "### Continuous variables\n",
    "These variables can take on any value within a range, and the differences between values are numerically meaningful.\n",
    "For example, pH can be 2.4, 7.0, 8.5, and so on, and any value between 0 and 14 is possible. Other examples of continuous variables include height, weight, and temperature. \n",
    "\n",
    "### Categorical variables\n",
    "These variables are descriptive and not numerical, and the differences between values are not numerically meaningful. \n",
    "For example, hair color, gum flavor, dog breed, and cloud type are all categorical variables. \n",
    "Categorical variables can be further classified into nominal data, which has no inherent order or ranking, and ordinal data, which has an inherent order or ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d67741-7829-4736-ac09-bbce6597cddb",
   "metadata": {},
   "source": [
    "## Question(6) How do we handle categorical variables in Machine Learning? What are the common techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e7d11-9409-4ce1-99f8-7d2248032773",
   "metadata": {},
   "source": [
    "Answer : Categorical data is a type of data that is used to group information with similar characteristics, \n",
    "         while numerical data is a type of data that expresses information in the form of numbers.\n",
    "         Example of categorical data: gender\n",
    "\n",
    "###  Here are some techniques for handling categorical variables in machine learning:\n",
    "### Label encoding\n",
    "Assigns a unique integer to each category in a categorical variable. This is useful for variables with \n",
    "many categories, but it can introduce ordinality into the data. \n",
    "\n",
    "### Ordinal encoding\n",
    "Similar to label encoding, but allows you to explicitly define the mapping between categories and integer labels. This is useful when there is a clear ordinal relationship between categories. \n",
    "\n",
    "### Target encoding\n",
    "Converts categorical variables into numerical values based on their relationship with the target variable. \n",
    "\n",
    "### Binary encoding\n",
    "Converts each category into its binary representation and splits the binary digits into separate columns. This method is more compact than one-hot encoding and is suitable for large datasets. \n",
    "\n",
    "### Frequency encoding\n",
    "Also known as count encoding, this technique assigns each category a numerical value representing how often it occurs in the dataset. \n",
    "\n",
    "### Dummy encoding\n",
    "Similar to one-hot encoding, this method transforms the categorical variable into a set of binary variables. \n",
    "\n",
    "### Hash encoding\n",
    "Uses hash operations to map categorical variables to a number of dimensions. This approach is useful for handling high cardinality squared variables. \n",
    "\n",
    "Other techniques for analyzing categorical data include chi-square tests for independence, logistic regression, multinomial regression, and correspondence analysis.\n",
    "\n",
    "* One-hot Encoding using:\n",
    "   * Python’s category_encoding library\n",
    "   * Scikit-learn preprocessing\n",
    "   * Pandas' get_dummies\n",
    "* Binary Encoding\n",
    "* Frequency Encoding\n",
    "* Label Encoding\n",
    "* Ordinal Encodin\n",
    "\n",
    "* Why do we need encoding?\n",
    "   * Most machine learning algorithms cannot handle categorical variables unless we convert them to numerical\n",
    "     values.\n",
    "   * Many algorithm’s performances even vary based upon how the categorical variables are encoded.\n",
    "\n",
    "* Categorical variables can be divided into two categories:\n",
    "   * Nominal: no particular order\n",
    "   * Ordinal: there is some order between values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c770503-8253-40f8-bc2a-3a6fc943318c",
   "metadata": {},
   "source": [
    "## Question(7) What do you mean by training and testing a dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82744e-9305-447e-bbd0-ace5a4e45558",
   "metadata": {},
   "source": [
    "Answer : Train/Test is a method to measure the accuracy of your model. It is called Train/Test because you \n",
    "         split the data set into two sets: a training set and a testing set. \n",
    "         80% for training, and 20% for testing. You train the model using the training set. \n",
    "         You test the model using the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b597a-ee4f-4900-9752-692f1a5088e5",
   "metadata": {},
   "source": [
    "## Question(8) What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db266d04-cb43-4049-ad7d-09d66614c99e",
   "metadata": {},
   "source": [
    "Answer : The sklearn. preprocessing package provides several common utility functions and transformer classes\n",
    "to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
    "In general, learning algorithms benefit from standardization of the data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7af1d-aa0e-4db6-af4c-c3facb0f823c",
   "metadata": {},
   "source": [
    "## Question(9) What is a Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74921bf8-efd2-42e5-95b2-f641cd33540c",
   "metadata": {},
   "source": [
    "Answer : A test set can refer to a group of test cases that are executed together or a portion of a dataset\n",
    "         used to evaluate a model's performance: \n",
    "\n",
    "* Group of test cases\n",
    "    A test set is a logical group of tests that are defined to be executed together. Test sets can contain \n",
    "    automated, manual, BDD, and exploratory tests. They can be used to define sets of tests for specific \n",
    "    purposes, such as smoke tests or regression tests. \n",
    "\n",
    "* Portion of a dataset\n",
    "    In machine learning, a test set is a portion of a dataset that is not used during model training.\n",
    "    The test set is used to evaluate the model's performance on unseen data. The purpose of the test set is\n",
    "    to ensure that the model's success is not due to memorization or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bdb3c-2536-4d62-a3ad-c8db12eb4661",
   "metadata": {},
   "source": [
    "## Question(10) How do we split data for model fitting (training and testing) in Python? \n",
    "##              How do you approach a Machine Learning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c830689-4d01-495a-8fe7-fd3b7aebc992",
   "metadata": {},
   "source": [
    "Answer : To split data for model fitting in Python, you can use the train_test_split() function from the \n",
    "         scikit-learn package: \n",
    "           * Import the train_test_split function\n",
    "           * Specify the dataset\n",
    "           * Set the test size\n",
    "\n",
    "The train_test_split() function randomly divides the data into training and testing sets, preserving the\n",
    "distribution of classes or outcomes. \n",
    "\n",
    "#### Here are some tips for splitting data for model fitting:\n",
    "* Split the data into features and labels: Before splitting the data, divide it into features (X) and labels \n",
    "  (y). \n",
    "\n",
    "* Keep the train set larger than the test set: It's generally recommended to keep the train set larger than \n",
    "  the test set. \n",
    "\n",
    "* Use group-based splitting: Group-based splitting can help ensure that the model generalizes the data well \n",
    "  and learns patterns deeply. This is important for real-world scenarios, where datasets often have \n",
    "  hierarchical structures. \n",
    "\n",
    "* Use the R-sq loss metric: The R-sq loss metric balances generalization with accuracy on the testing set. \n",
    "  It produces a single number for judging a model's performance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3e48e-1438-4a60-bb36-ec76dfa1a5c8",
   "metadata": {},
   "source": [
    "### Splitting Data for Model Fitting (Training and Testing) in Python\n",
    "In machine learning, splitting data into training and testing sets ensures the model's ability to generalize \n",
    "well to unseen data. Here's how you can do it in Python:\n",
    "\n",
    "### 1. Using train_test_split from scikit-learn\n",
    "The most common method is using the train_test_split function from the scikit-learn library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb99296d-35b7-49ad-bfd9-7935bd516df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[ 3  4]\n",
      " [ 9 10]\n",
      " [ 1  2]\n",
      " [ 7  8]]\n",
      "X_test: [[5 6]]\n",
      "y_train: [1 0 0 1]\n",
      "y_test: [0]\n"
     ]
    }
   ],
   "source": [
    "## Import the library\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])             # Features\n",
    "y = np.array([0, 1, 0, 1, 0])                                       # Labels\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"X_train:\", X_train)\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"y_test:\", y_test)\n",
    "\n",
    "\n",
    "# Parameters:\n",
    "# test_size: Fraction of the dataset for testing (e.g., 0.2 = 20% test data).\n",
    "# random_state: Seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145f661-22cb-4742-9c3c-f8ce053caa94",
   "metadata": {},
   "source": [
    "### 2. Further Splitting for Validation\n",
    "You can also split data into training, validation, and testing sets for better evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4545a783-7aa8-4b3a-89e3-06a68bf2ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fbfbb6a-20cd-4f73-bc2f-04bce15464d3",
   "metadata": {},
   "source": [
    "This results in:\n",
    "\n",
    "60% training data\n",
    "20% validation data\n",
    "20% testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48a0f1-8eff-4f69-8716-56ae0d019037",
   "metadata": {},
   "source": [
    "### 3. Stratified Splitting (for Classification Problems)\n",
    "If you want the splits to preserve the class distribution:\n",
    "The stratify=y argument ensures the proportions of classes in the split are similar to the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb46f7-d921-40d1-a4ee-55aa87b42bbc",
   "metadata": {},
   "source": [
    "### Approaching a Machine Learning Problem\n",
    "Approaching a machine learning problem involves several structured steps:\n",
    "\n",
    "#### 1. Understand the Problem\n",
    "Clearly define the problem: Is it classification, regression, clustering, etc.?\n",
    "Understand the business or practical objectives.\n",
    "Determine the success criteria (e.g., accuracy, F1-score, RMSE).\n",
    "\n",
    "#### 2. Collect and Prepare Data\n",
    "* Gather the dataset (from sources like CSV files, databases, APIs).\n",
    "* Inspect the data for completeness, format, and consistency.\n",
    "* Perform data cleaning:\n",
    "    * Handle missing values.\n",
    "    * Remove duplicates.\n",
    "    * Correct invalid entries.\n",
    "\n",
    "#### 3. Exploratory Data Analysis (EDA)\n",
    "* Analyze the dataset’s structure, distributions, and patterns.\n",
    "* Use visualization tools like matplotlib and seaborn to understand relationships.\n",
    "* Identify outliers, correlations, and biases.\n",
    "\n",
    "#### 4. Feature Engineering\n",
    "* Select relevant features or create new ones (feature extraction).\n",
    "* Encode categorical variables (e.g., one-hot encoding or label encoding).\n",
    "* Scale numerical features (e.g., normalization or standardization).\n",
    "\n",
    "#### 5. Split Data\n",
    "* Split the dataset into training, validation, and testing sets.\n",
    "* Ensure proper stratification if dealing with imbalanced datasets.\n",
    "\n",
    "#### 6. Select and Train a Model\n",
    "* Choose a suitable model or algorithm based on the problem type.\n",
    "* Train the model using the training data.\n",
    "* Use cross-validation to avoid overfitting.\n",
    "\n",
    "#### 7. Evaluate the Model\n",
    "* Evaluate using appropriate metrics:\n",
    "     * Classification: Accuracy, precision, recall, F1-score, AUC-ROC.\n",
    "     * Regression: MSE, RMSE, MAE, R².\n",
    "\n",
    "* Use the validation set for hyperparameter tuning.\n",
    "\n",
    "#### 8. Optimize\n",
    "* Perform hyperparameter tuning using techniques like grid search or random search.\n",
    "* Test ensemble methods (e.g., Random Forest, Gradient Boosting).\n",
    "\n",
    "#### 9. Test and Deploy\n",
    "* Evaluate the final model on the unseen test dataset.\n",
    "* Deploy the model to production.\n",
    "* Monitor the model's performance over time.\n",
    "\n",
    "#### 10. Iterate and Improve\n",
    "Machine learning is iterative. Revisit steps to improve the model's performance based on feedback and new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c686375-5bef-49f9-ae07-6ec76473dcdd",
   "metadata": {},
   "source": [
    "## Question(11) Why do we have to perform EDA before fitting a model to the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20769ccb-f01f-437c-8b95-d96a1e0b01da",
   "metadata": {},
   "source": [
    "Answer : Exploratory Data Analysis (EDA) is the process of analyzing and summarizing datasets to uncover \n",
    "patterns, spot anomalies, and test hypotheses. It serves as a crucial step in the data analysis and machine \n",
    "learning workflow to gain insights into the data before applying algorithms or statistical models.\n",
    "\n",
    "* Before fitting any model, it is often important to conduct an exploratory data analysis (EDA) in order to \n",
    "  check assumptions, inspect the data for anomalies (such as missing, duplicated, or mis-coded data), and \n",
    "  inform feature selection/transformation.\n",
    "\n",
    "### Exploratory Data Analysis (EDA) is important to perform before fitting a model to data because it helps you:\n",
    "\n",
    "* Check Assumptions\n",
    "   >EDA helps you avoid faulty analysis by ensuring you don't make assumptions or conclutions before \n",
    "   examining the data.\n",
    "\n",
    "* Identify Anomalies\n",
    "   >EDA helps you inspect the data for issues like : missing,duplicated or mis-coded data.\n",
    "* Inform Feature Selection\n",
    "   >EDA helps you identify variables that need to be normalized,scaled or encoded to improve model \n",
    "   performance.\n",
    "\n",
    "* Understand the Data\n",
    "   >EDA helps you understand the data set variables and the relationships between them.\n",
    "##### EDA is the initial examination of data and should be performed before making any changes to the data set or developing a statistical model. The quality and integrity of the data set is important for the effectiveness of EDA. Data Cleaning is often a preparatory step to improve the quality of the data by finding and fixing errors and inconsistencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b6423-298f-4827-9127-0b0026b08499",
   "metadata": {},
   "source": [
    "## Question(12) What is correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94232f96-cee6-4895-a262-907a5d5b0c91",
   "metadata": {},
   "source": [
    "Answer : Correlation in machine learning is a statistical measurement of the relationship between two or \n",
    "more variables. It's a key part of data exploration and is used in many advanced machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9b449-9d36-48b2-9451-2b93204f9147",
   "metadata": {},
   "source": [
    "## Question(13) What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bab96d-64e4-43f4-8c47-81a68600e908",
   "metadata": {},
   "source": [
    "Answer :\n",
    "* In machine learning, negative correlation is when two variables move in opposite directions, so that\n",
    "  an increase in one variable causes a decrease in the other.\n",
    "\n",
    "* Negative correlation is also known as an inverse correlation. The strength of the negative correlation can\n",
    "  vary, and can be represented by a correlation coefficient.\n",
    "  For example, a correlation coefficient of -0.9 means that for every positive change in variable B, variable\n",
    "   A decreases by 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a509a00-6fdf-4d75-ba5b-2037c832dc21",
   "metadata": {},
   "source": [
    "## Question(14) How can you find correlation between variables in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dde6ea-ce1e-46b9-b9d8-65d782092cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : In Python, we can calculate the correlation between variables using various libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ec78f-2d40-4b72-ab49-91930b84f4a8",
   "metadata": {},
   "source": [
    "### 1. Using pandas\n",
    "The pandas library provides the .corr() method to compute correlation coefficients for a DataFrame or between\n",
    "two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe22cbf-3d42-423f-bc7f-80cce175cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X    Y\n",
      "X  1.0  1.0\n",
      "Y  1.0  1.0\n",
      "Correlation between X and Y: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {'X': [1, 2, 3, 4, 5], 'Y': [6, 7, 8, 9, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Correlation between specific variables\n",
    "correlation = df['X'].corr(df['Y'])\n",
    "print(f\"Correlation between X and Y: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19562a-3a54-4f75-b1cd-5c4a9cfb8bf5",
   "metadata": {},
   "source": [
    "### 2. Using numpy\n",
    "The numpy library has a np.corrcoef() function to calculate Pearson's correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5960eb6-d4d9-43f4-bc22-621b9e2253cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "Correlation between X and Y: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = [1, 2, 3, 4, 5]\n",
    "Y = [6, 7, 8, 9,10]\n",
    "\n",
    "# Correlation coefficient matrix\n",
    "correlation_matrix = np.corrcoef(X, Y)\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Pearson's correlation coefficient\n",
    "correlation = correlation_matrix[0, 1]\n",
    "print(f\"Correlation between X and Y: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf1130-2d3a-4481-a287-c20e7da16fe3",
   "metadata": {},
   "source": [
    "## 3. Using scipy\n",
    "* The scipy.stats module provides functions for different types of correlation:\n",
    "   * Pearson correlation: scipy.stats.pearsonr\n",
    "   * Spearman correlation: scipy.stats.spearmanr\n",
    "   * Kendall Tau correlation: scipy.stats.kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c78ac2cf-ad90-4673-b898-163ad4c65f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 1.0\n",
      "Spearman correlation: 0.9999999999999999\n",
      "Kendall Tau correlation: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "# Example data\n",
    "X = [1, 2, 3, 4, 5]\n",
    "Y = [6, 7, 8, 9,10]\n",
    "\n",
    "# Pearson correlation\n",
    "pearson_corr, _ = pearsonr(X, Y)\n",
    "print(f\"Pearson correlation: {pearson_corr}\")\n",
    "\n",
    "# Spearman correlation\n",
    "spearman_corr, _ = spearmanr(X, Y)\n",
    "print(f\"Spearman correlation: {spearman_corr}\")\n",
    "\n",
    "# Kendall Tau correlation\n",
    "kendall_corr, _ = kendalltau(X, Y)\n",
    "print(f\"Kendall Tau correlation: {kendall_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d10047-5fc6-4726-bdcf-f46576aa024d",
   "metadata": {},
   "source": [
    "### 4. Using Visualization (e.g., seaborn)\n",
    "we can visualize the correlation matrix using heatmaps for better interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f59fe49c-d655-44eb-aa2a-d722adbb01bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "data = {'X': [1, 2, 3, 4, 5], 'Y': [12, 15, 18, 19,10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8138fa-183a-4554-a070-9089ad26397a",
   "metadata": {},
   "source": [
    "* Choose the appropriate correlation method (pearson, spearman, or kendall) based on the data distribution \n",
    "  and requirements:\n",
    "    * Pearson: Linear correlation.\n",
    "    * Spearman: Monotonic relationships (non-linear correlations).\n",
    "    * Kendall: Ordinal data or small sample sizes.\n",
    "\n",
    "\n",
    "* Always inspect the data before computing correlations to ensure accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c6076-ad27-46f7-a085-f9d37a3bb317",
   "metadata": {},
   "source": [
    "## Question(15) What is causation? Explain difference between correlation and causation with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2cc1b-de35-46aa-93ad-8a80018045d7",
   "metadata": {},
   "source": [
    "Answer : Causation means that one event directly causes another, while correlation is when two things happen\n",
    "together but one doesn't cause the other.\n",
    "\n",
    "### Causation \n",
    "* Causation refers to a relationship where one variable (cause) directly affects another variable \n",
    "  (effect).\n",
    "\n",
    "* In other words, changes in one variable bring about changes in the other. This relationship implies a\n",
    "         cause-and-effect mechanism.\n",
    "\n",
    "### Correlation vs. Causation\n",
    "* While correlation is a statistical measure that describes the degree to which two variables move\n",
    "  together,it does not imply that one variable causes the other.\n",
    "\n",
    "* Causation, on the other hand, confirms that one variable directly influences the other.\n",
    "\n",
    "###  Key Differences\n",
    " \n",
    "### Correlation\n",
    "#### Aspect\t                \n",
    "* Definition    :  Measures how two variables move in relation to each other.\t\n",
    "* Direction     :  Can be positive, negative, or zero.\n",
    "* Proof Needed  :\t Statistical correlation is sufficient.\n",
    "* Example       :\t Ice cream sales and drowning rates are correlated.\t\n",
    "\n",
    "### Causation\n",
    "#### Aspect\n",
    "* Defination    :  Establishes that one variable affects the other.\n",
    "* Direction     :  Implies a direct cause-effect relationship.\n",
    "* Proof Needed  :  Requires evidence from experiments, interventions, or robust causal analysis\n",
    "* Example       :  Smoking causes lung cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e5eae-8dac-4c3d-b32c-f5824f3e72ef",
   "metadata": {},
   "source": [
    "## Question(16) What is an Optimizer? What are different types of optimizers? Explain each with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a33b6-821b-4d17-9268-592f93a1daf8",
   "metadata": {},
   "source": [
    "Answer : Optimizers are techniques or algorithms used to decrease loss (an error) by tuning various parameters and weights, hence minimizing the loss function.\n",
    "\n",
    "* An optimizer is a mathematical function or algorithm that modifies a neural network's attributes to \n",
    "  improve accuracy and reduce loss. Optimizers help find the best set of parameters, such as weights and \n",
    "  learning rate, for a model. The goal of an optimizer is to improve the model’s accuracy by iteratively \n",
    "  updating its parameters.Optimizers play a key role in training models efficiently and effectively, as they \n",
    "  determine how the model navigates the loss landscape to reach an optimal solution.\n",
    "\n",
    "* Types of optimizers:\n",
    "   * 1. Gradient Descent (GD)\n",
    "        >* An optimization algorithm that uses a convex function to iteratively tweak parameters to minimize \n",
    "           a function to its local minimum.\n",
    "        \n",
    "        >* How it works: Gradient descent calculates the gradient of the loss function with respect to the \n",
    "           model parameters (weights and biases) using the entire training dataset. It updates the \n",
    "           parameters by taking a step in the opposite direction of the gradient.\n",
    "        \n",
    "        >* Example:\n",
    "               Pseudo code for gradient descent\n",
    "               for epoch in range(epochs):\n",
    "                gradients = compute_gradients(data, labels)\n",
    "                parameters = parameters - learning_rate * gradients\n",
    "        \n",
    "        >* Advantages: Straightforward implementation.\n",
    "        >* Disadvantages: Slow for large datasets, as it processes the entire dataset per iteration.\n",
    "\n",
    "   * 2. Stochastic Gradient Descent (SGD)\n",
    "        >* An extension of gradient descent that overcomes some of its disadvantages by computing the \n",
    "           derivative of one point at a time.\n",
    "        \n",
    "        >* How it works: Unlike GD, SGD updates parameters using one data sample at a time, reducing \n",
    "           computational cost and introducing randomness.\n",
    "        \n",
    "        >* Example: SGD Example\n",
    "                      for epoch in range(epochs):\n",
    "                      for i in range(len(data)):\n",
    "                          gradient = compute_gradient(data[i], labels[i])\n",
    "                          parameters = parameters - learning_rate * gradient\n",
    "        \n",
    "        >* Advantages: Faster updates, especially for large datasets.\n",
    "        >* Disadvantages: Noisy updates can cause instability.\n",
    "\n",
    "   * 3. Mini-Batch Gradient Descent\n",
    "        >* How it works: Mini-batch GD strikes a balance between GD and SGD by computing gradients over \n",
    "           small batches of data.\n",
    "        \n",
    "        >* batch_size = 32\n",
    "           for epoch in range(epochs):\n",
    "           for batch in create_batches(data, batch_size):\n",
    "               gradient = compute_gradient(batch)\n",
    "               parameters = parameters - learning_rate * gradient\n",
    "        \n",
    "        >* Advantages: Reduces noise while being computationally efficient.\n",
    "        >* Disadvantages: Requires tuning the batch size\n",
    "   \n",
    "   * 4. RMSprop (Root Mean Square Propagation)\n",
    "        > Stands for Root Mean Square Propagation, this optimizer accumulates gradients in a fixed window \n",
    "          instead of letting them accumulate for momentum.\n",
    "        > How it works: Normalizes the learning rate by dividing by the root mean square of recent \n",
    "                        gradients, which helps handle varying gradient magnitudes.\n",
    "        \n",
    "        >* Example:\n",
    "               import tensorflow as tf\n",
    "               optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "        \n",
    "        >* Advantages: Works well for RNNs and non-stationary objectives.\n",
    "\n",
    "\n",
    "   * 5. Nesterov Accelerated Gradient (NAG)\n",
    "        >* A way to give the momentum term prescience by computing an approximation of the next position of \n",
    "           the parameters.\n",
    "        \n",
    "        >* How it works: Improves momentum-based optimizers by looking ahead to estimate the future position \n",
    "                         and computing the gradient at that position.\n",
    "        \n",
    "        >* Example:\n",
    "              optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "        \n",
    "        >* Advantages: Often converges faster and reduces overshooting. \n",
    "\n",
    "\n",
    "  * 6. Adam (Adaptive Moment Estimation)\n",
    "       >* How it works: Combines momentum and RMSprop. It maintains moving averages of the gradient and its \n",
    "             square and uses these to adaptively adjust the learning rate for each parameter.\n",
    "\n",
    "       >* Example :\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "       >* Advantages:\n",
    "               >* Works well across most problems.\n",
    "               >* Requires minimal tuning.\n",
    "\n",
    "\n",
    "  * 7. Adagrad (Adaptive Gradient Algorithm)\n",
    "       >* How it works: Adjusts the learning rate for each parameter based on the sum of squares of gradients.\n",
    "       >* Example:\n",
    "              optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "\n",
    "       >* Advantages: Suitable for sparse data.\n",
    "\n",
    "  * 8. Adadelta\n",
    "       >* How it works: A variation of Adagrad that limits the accumulation of past gradients to address its diminishing learning rate problem.\n",
    "       >* Example:\n",
    "              optimizer = tf.keras.optimizers.Adadelta()\n",
    "\n",
    "       >* Advantages: Robust learning rate adjustment.\n",
    "\n",
    "* The right optimizer to use depends on the specific deep-learning task and the characteristics of the data.\n",
    "* Choosing the Right Optimizer\n",
    "     >* Adam is often the default choice due to its robustness.\n",
    "     >* Use SGD with momentum or NAG for smooth and fast convergence.\n",
    "     >* Consider RMSprop or Adadelta for sequence models or non-stationary data.\n",
    "     \n",
    "* Experimentation and fine-tuning are key to selecting the best optimizer for your specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7a374-49c6-4bb0-b72f-f0954cadc68b",
   "metadata": {},
   "source": [
    "## Question(17) What is sklearn.linear_model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa3d43-a299-4c5c-b276-a9a8abb62186",
   "metadata": {},
   "source": [
    "Answer : linear_model is a class of the sklearn module if contain different functions for performing machine learning with linear models.\n",
    "The term linear model implies that the model is specified as a linear combination of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b1da1-fe1e-448b-9fe1-624def063548",
   "metadata": {},
   "source": [
    "## Question(18) What does model.fit() do? What arguments must be given?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a5f74-9078-4b24-b117-44f38418d79b",
   "metadata": {},
   "source": [
    "Answer : \n",
    "* The model.fit() method in machine learning libraries like Scikit-Learn, TensorFlow, or PyTorch trains a model using the provided data. It \n",
    "  calculates the relationship between the features (X) and labels (y) (for supervised learning) or identifies patterns in the data (for \n",
    "  unsupervised learning).\n",
    "\n",
    "* The fit() method in Scikit-Learn is used to train a machine learning model. Training a model involves feeding it with data so it can learn the\n",
    "  underlying patterns. This method adjusts the parameters of the model based on the provided data.\n",
    "\n",
    "* Arguments Required for fit()\n",
    "\n",
    "  * The exact arguments depend on the library and type of model, but here’s a general overview:\n",
    "\n",
    "  * For Supervised Learning Models (e.g., Scikit-Learn)\n",
    "      1. X (required):\n",
    "          * A 2D array-like structure (e.g., a NumPy array, Pandas DataFrame) of shape (n_samples, n_features).\n",
    "          * Represents the independent variables or input features.\n",
    "      \n",
    "      2. y (required for supervised learning):\n",
    "          * A 1D array-like structure (e.g., a NumPy array, Pandas Series) of shape (n_samples,).\n",
    "          * Represents the target values or dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49ee3e5d-5767-4801-b2cf-e31ec498f099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example in Scikit-Learn:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Features and target\n",
    "X = [[1], [2], [3]]  # Independent variables\n",
    "y = [2, 4, 6]        # Dependent variable\n",
    "\n",
    "# Initialize and train model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d70995-7f34-4a2e-bab8-09b9d3b5c4f7",
   "metadata": {},
   "source": [
    "* For Unsupervised Learning Models:\n",
    "    1. X (required):\n",
    "        * The feature matrix, as above.\n",
    "\n",
    "    2. y (optional or not used):\n",
    "        * In algorithms like clustering, y is not required since there are no labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4e4cb755-613e-42cf-9e69-8c8e54bc09db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example in Scikit-Learn (K-Means Clustering):\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Features\n",
    "X = [[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]]\n",
    "\n",
    "# Initialize and train model\n",
    "model = KMeans(n_clusters=2)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b51a8-e29d-47c4-b422-df8935e867f7",
   "metadata": {},
   "source": [
    "* For Neural Networks (e.g., TensorFlow/Keras):\n",
    "    1. X (required):\n",
    "         * Feature matrix, typically a NumPy array or TensorFlow tensor.\n",
    "\n",
    "    2. y (required for supervised learning):\n",
    "         * Target labels, in the same format as above.\n",
    "\n",
    "    3. Additional Arguments:\n",
    "         * batch_size: Number of samples processed per batch.\n",
    "         * epochs: Number of complete passes through the dataset.\n",
    "         * validation_data: Optional data for validation during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c429d-a629-4f9a-a7b1-8a2034b52fc4",
   "metadata": {},
   "source": [
    "* The fit() method is used to train a model by optimizing its parameters.\n",
    "* Required Arguments:\n",
    "   >* X: Feature matrix.\n",
    "   >* y: Target values (for supervised learning).\n",
    "\n",
    "* Additional Arguments:\n",
    "   >* batch_size, epochs, validation_data, and others depending on the library and model type.\n",
    "\n",
    "* By calling fit(), the model learns from the training data and becomes ready for tasks like prediction, evaluation, or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d5d0b-1ab7-421e-b4f8-4fd878dd8e08",
   "metadata": {},
   "source": [
    "## Question(19) What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9365346-53b6-457e-9822-cd07dca2224c",
   "metadata": {},
   "source": [
    "Answer : The model.predict() method in machine learning libraries like TensorFlow/Keras or Scikit-Learn is\n",
    "used to generate predictions based on a trained model. After the model has been trained with fit() \n",
    "(or equivalent), predict() takes input data (features) and outputs the corresponding predicted values.\n",
    "\n",
    "* Arguments for model.predict()\n",
    "    1. Required Argument\n",
    "         * X (or equivalent):\n",
    "             >* The input data for which predictions are to be made.\n",
    "             >* Format:\n",
    "\n",
    "                             * Scikit-Learn: Array-like of shape (n_samples, n_features).\n",
    "                             * TensorFlow/Keras: NumPy arrays, tensors, or similar structures.\n",
    "\n",
    "            >* Example: Feature data (test or new data).\n",
    "\n",
    "     2. Optional Arguments\n",
    "          * Batch Size:\n",
    "\n",
    "                * For deep learning models, you can specify how many samples are processed at a time.\n",
    "                * Default: Uses all data in one batch.\n",
    "                * Example in Keras:\n",
    "                       predictions = model.predict(X, batch_size=32)\n",
    "\n",
    "           * Verbose:\n",
    "             > Controls logging output during prediction:\n",
    "\n",
    "                            * 0: No output.\n",
    "                            * 1: Progress bar (TensorFlow/Keras).\n",
    "\n",
    "             > Example:\n",
    "                       predictions = model.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88e842-ea34-4664-beba-d64bdc071ea0",
   "metadata": {},
   "source": [
    "## Question(20) What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb876c0-fecc-444d-84cf-4ac145499c36",
   "metadata": {},
   "source": [
    "Answer : Continuous variables are values that can take on any value within a range, while categorical \n",
    "variables are descriptive and not numerical: \n",
    "\n",
    "### Continuous variables\n",
    "* These variables can take on any value within a range, and the differences between values are numerically \n",
    "  meaningful. \n",
    "\n",
    "* For example, pH can be 2.4, 7.0, 8.5, and so on, and any value between 0 and 14 is possible. Other \n",
    "  examples of continuous variables include height, weight, and temperature. \n",
    "\n",
    "### Categorical variables\n",
    "* These variables are descriptive and not numerical and the differences between values are not numerically \n",
    "  meaningful.\n",
    "\n",
    "* For example, hair color, gum flavor, dog breed, and cloud type are all categorical variables. \n",
    "\n",
    "* Categorical variables can be further classified into nominal data, which has no inherent order or ranking, \n",
    "  and ordinal data, which has an inherent order or ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c84ca-0c99-4ac2-bbbe-13efd99a6ad4",
   "metadata": {},
   "source": [
    "## Question (21) What is feature scaling? How does it help in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe07d3-3bb3-4ba3-acb4-4f18f77d83ec",
   "metadata": {},
   "source": [
    "Answer :\n",
    "* Feature scaling is a process that transforms the values of independent variables in a dataset to a common\n",
    "  range or scale. The goal is to ensure that all features are treated equally by a model, and that the \n",
    "  model's performance is not negatively impacted by changing value distributions. \n",
    "\n",
    "* Feature scaling is often used in data processing and machine learning to improve the accuracy of outcomes\n",
    "  and speed up computations. It can be especially beneficial for models that are sensitive to the range of\n",
    "  data points, such as Support Vector Machines (SVM) and k-nearest neighbors (k-NN).\n",
    "\n",
    "* How Feature Scaling Helps in Machine Learning\n",
    "   1. Improves Model Performance:\n",
    "        * Many algorithms (e.g., KNN, SVM, Gradient Descent-based models) use distance-based or gradient- \n",
    "          based methods, which can be sensitive to the scale of the features. If one feature has a much \n",
    "          larger range than others, it can dominate the model's behavior, leading to poor performance.\n",
    "\n",
    "   2. Faster Convergence in Optimization Algorithms:\n",
    "        * In gradient-based methods (like Gradient Descent), feature scaling helps achieve faster convergence\n",
    "          by ensuring that all features move at similar speeds during the optimization process. This can \n",
    "          significantly reduce training time.\n",
    "    \n",
    "   3. Ensures Equal Weighting of Features:\n",
    "        * Without scaling, features with larger numeric ranges will have more influence on the model. \n",
    "        * For example, in a dataset where one feature is \"age\" ranging from 0 to 100, and another is \"income\"\n",
    "          ranging from 1,000 to 100,000, income would dominate without scaling.\n",
    "\n",
    "   4. Improves Accuracy:\n",
    "        * Some algorithms assume that all features are centered around zero and have similar ranges\n",
    "          (like linear regression or neural networks).Feature scaling helps these models better fit the data.\n",
    "              \n",
    "   5. Enhances Interpretability:\n",
    "        * Standardization makes it easier to compare the importance of features in certain model.\n",
    "           (e.g., in linear regression, where the coefficients can be interpreted after scaling).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb657d-2ed7-4d22-95b1-f1a94edcc13d",
   "metadata": {},
   "source": [
    "## Question(22) How do we perform scaling in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1290cc-70d2-46fd-b5b1-d02d9d314403",
   "metadata": {},
   "source": [
    "Answer : Scaling in Python is a process that involves transforming data to ensure that features have values\n",
    "in the same range. It's an important step to take before model building because it can increase a model's \n",
    "predictive power.\n",
    "\n",
    "* Here are some scaling techniques in Python:\n",
    "### Standardization\n",
    "Also known as Z-score normalization, this technique rescales features so that they have a mean of 0 \n",
    "and a standard deviation of 1. It's useful when the distribution of features is not uniform.\n",
    "\n",
    "### Min-max normalization\n",
    "Also known as normalization,this technique transforms features to fit within a specific range, usually between zero and 1. It's useful when you want to preserve the relationships among the original data points.\n",
    "\n",
    "* Scaling can help to:\n",
    "  >* Ensure that features used in model building are dimensionless.\n",
    "  >* Detect outliers.\n",
    "  >* Reduce potential biases and inconsistencies that may arise from variations in feature values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dab5d0-0b7e-4a4b-a8a4-57acb78a6f74",
   "metadata": {},
   "source": [
    "## Question(23) What is sklearn.preprocessing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0c96d-44b8-4c05-94fb-72d341f3387b",
   "metadata": {},
   "source": [
    "Answer : The sklearn. preprocessing package provides several common utility functions and transformer classes\n",
    "to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
    "In general, learning algorithms benefit from standardization of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba94180-e943-4398-bcae-37165b1f5954",
   "metadata": {},
   "source": [
    "## Question(24) How do we split data for model fitting (training and testing) in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde863fd-5b5e-4602-89f8-d9bf69cd79c6",
   "metadata": {},
   "source": [
    "Answer :\n",
    "* To split data for model fitting in Python, you can use the train_test_split() function from the \n",
    "  scikit-learn library: \n",
    "      >1. Import the train_test_split function\n",
    "      >2. Specify the dataset\n",
    "      >3. Set the test size\n",
    "\n",
    "* The train_test_split() function randomly divides the data into training and testing sets. It preserves the\n",
    "  distribution of classes or outcomes.\n",
    "\n",
    "* Here are some tips for splitting data for model fitting:\n",
    "  \n",
    "### Arrange the data\n",
    "Before splitting the data, make sure it's arranged into a format that's acceptable for train-test split. In scikit-learn, this means separating the data into \"Features\" and \"Target\". \n",
    "\n",
    "### Keep the train set larger than the test set\n",
    "It's generally recommended to keep the train set larger than the test set. \n",
    "\n",
    "### Use group-based splitting\n",
    "Group-based splitting can help ensure that the model generalizes the data well and learns patterns deeply. It's especially important when working with real-world datasets, which often have hierarchical structures. \n",
    "\n",
    "### Use 20-30% for testing\n",
    "Empirical studies show that the best results are obtained when 20-30% of the data is used for testing, and the remaining 70-80% is used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39fe3a-7c66-477f-9a13-7b02f6f78a9f",
   "metadata": {},
   "source": [
    "## Question(25) Explain data encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfb1c0-e54c-4d2d-8258-4e9a72312525",
   "metadata": {},
   "source": [
    "Answer : Data encoding is the process of converting information into a specific format for communication or \n",
    "storage. It's a crucial concept in computing and technology.\n",
    "\n",
    "### Here are some examples of data encoding:\n",
    "* Programming : Encoding Data into a specific format for transmission or storage.\n",
    "  >For Example : We can Encode text in unicode to represent characters in a standardized way.\n",
    "\n",
    "* Data compression : Encoding can help represent information more efficiently.\n",
    "\n",
    "* Machine Learning : Encoding categorical variables into numerical representations so that machine learning \n",
    "  algorithms can understand them.\n",
    "  >For Example : We can use one-hot encoding, label encoding or ordinal encoding.\n",
    "  \n",
    "* Data Transmission : Encoding is important for secure data transmission.\n",
    "\n",
    "#### The reverse process of Encoding is DECODING,Which is extracting information from the converted format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b59069-1543-4d65-8f05-f1666a7ecb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2cb7c-aa9c-4c5e-bef2-b109482fa21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
